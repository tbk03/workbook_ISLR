<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Statistical Learning | Workbook: An Introduction to Statistical Learning</title>
  <meta name="description" content="This is a workbook where I work through the exercises in An Introduction to Statistical Learning" />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Statistical Learning | Workbook: An Introduction to Statistical Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a workbook where I work through the exercises in An Introduction to Statistical Learning" />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Statistical Learning | Workbook: An Introduction to Statistical Learning" />
  
  <meta name="twitter:description" content="This is a workbook where I work through the exercises in An Introduction to Statistical Learning" />
  

<meta name="author" content="Chris J. Martin" />


<meta name="date" content="2021-06-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="linear-regression.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="https://tbk03.github.io/portfolio/index.html">Chris J. Martin</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a></li>
<li class="chapter" data-level="2" data-path="statistical-learning.html"><a href="statistical-learning.html"><i class="fa fa-check"></i><b>2</b> Statistical Learning</a>
<ul>
<li class="chapter" data-level="2.1" data-path="statistical-learning.html"><a href="statistical-learning.html#conceptual-exercises"><i class="fa fa-check"></i><b>2.1</b> Conceptual Exercises</a></li>
<li class="chapter" data-level="2.2" data-path="statistical-learning.html"><a href="statistical-learning.html#applied-exercises"><i class="fa fa-check"></i><b>2.2</b> Applied Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="linear-regression.html"><a href="linear-regression.html"><i class="fa fa-check"></i><b>3</b> Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="linear-regression.html"><a href="linear-regression.html#lab"><i class="fa fa-check"></i><b>3.1</b> Lab</a></li>
<li class="chapter" data-level="3.2" data-path="linear-regression.html"><a href="linear-regression.html#conceptual-questions"><i class="fa fa-check"></i><b>3.2</b> Conceptual questions</a></li>
<li class="chapter" data-level="3.3" data-path="linear-regression.html"><a href="linear-regression.html#applied-questions"><i class="fa fa-check"></i><b>3.3</b> Applied questions</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Workbook: An Introduction to Statistical Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="statistical-learning" class="section level1" number="2">
<h1><span class="header-section-number">Chapter 2</span> Statistical Learning</h1>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="statistical-learning.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code></pre></div>
<pre><code>## Warning: package &#39;tidyverse&#39; was built under R version 4.0.5</code></pre>
<pre><code>## -- Attaching packages --------------------------------------- tidyverse 1.3.1 --</code></pre>
<pre><code>## v ggplot2 3.3.3     v purrr   0.3.4
## v tibble  3.1.0     v dplyr   1.0.5
## v tidyr   1.1.3     v stringr 1.4.0
## v readr   1.4.0     v forcats 0.5.1</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 4.0.4</code></pre>
<pre><code>## Warning: package &#39;tibble&#39; was built under R version 4.0.5</code></pre>
<pre><code>## Warning: package &#39;tidyr&#39; was built under R version 4.0.4</code></pre>
<pre><code>## Warning: package &#39;dplyr&#39; was built under R version 4.0.4</code></pre>
<pre><code>## Warning: package &#39;forcats&#39; was built under R version 4.0.4</code></pre>
<pre><code>## -- Conflicts ------------------------------------------ tidyverse_conflicts() --
## x dplyr::filter() masks stats::filter()
## x dplyr::lag()    masks stats::lag()</code></pre>
<div id="conceptual-exercises" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Conceptual Exercises</h2>
<p><strong>Question 1: Flexible and inflexible statistical learning methods.</strong></p>
<p><em>(a):</em> If sample size (n) is very large and the number of predictors is small (p) I would expect a flexible statistical learning method to perform better than an inflexible method. This is where sample sizes are large one can assume that the variance will be a lesser contributor to the irreducible error than bias. And, the bias of the more flexible method will be lower than the bias of the more flexible method.</p>
<p><em>(b):</em> If there is a large number of predictors (p) and a small number of data points (n) I would expect a flexible statistical learning method to perform worse than an inflexible method. This is because a flexible method would be likely to have high variance (i.e. the component of the reducible error associated with the differences between model prediction over different training sets). Hence, the more flexible method would be more prone to overfitting the small number of training data points (than the inflexible method) and in turn be likely to return worse results. This is of course a generalisation and the performance of flexible vs. inflexible methods varies from dataset to dataset.</p>
<p><em>(c):</em> If the relationship between the response variable and the predictor variables is highly non linear I would expect a flexible statistical learning method to perform better than an inflexible method. This is because a relatively inflexible methods (such as linear regression) tend to have assumptions around linearity embedded within them, whereas more flexible methods do not (e.g. splines).</p>
<p><em>(d):</em> If the variance of the error terms is extremely high I would expect a flexible statistical learning method to perform worse than an inflexible method. This is because with a flexible model there would a tendency to overfit the large amount noise (i.e. very high variance in error terms) in the data. Whereas, the less flexible method would be less sensitive to the noise and in many cases could well do a better job of extracting the signal (i.e. relationship) between the predictors and the response variable.</p>
<p><strong>Question 2: Regression or classification problems.</strong></p>
<p><em>(a):</em></p>
<ul>
<li><p>Problem type: regression (salary is a continuous variable);</p></li>
<li><p>n = 500;</p></li>
<li><p>and, p = 3.</p></li>
</ul>
<p><em>(b):</em></p>
<ul>
<li><p>Problem type: classification (success or failure is a binary variable);</p></li>
<li><p>n = 20;</p></li>
<li><p>and, p = 13.</p></li>
</ul>
<p><em>(c):</em></p>
<ul>
<li><p>Problem type - regression (% change is a continuous variable);</p></li>
<li><p>n = 52;</p></li>
<li><p>and, p = 3.</p></li>
</ul>
<p><strong>Question 3: Bias-variance decomposition</strong></p>
<p><em>(a):</em> sketched in paper notebook.</p>
<p><em>(b):</em> describing the shape of typical error curves</p>
<ul>
<li><p>Bias (squared) - reduces as the flexibility of method increases because the bias represents the errors by approximating and simplifying a real world system. Less flexible methods apply more simplifications than flexible methods and hence have greater bias.</p></li>
<li><p>Variance - increase as the flexibility of a method increases because the variance represents the error arising from sample process. More flexible methods are more closely fitted to the specific features of the data than less flexible models. So, overfitting of the current sample increases of model flexibility, driving increases in variance errors.</p></li>
<li><p>The Training error - decrease as the flexibility of a method increases (following the bias curve plus the irreducible error). This is because variance errors are not evident in fitting to the training set, rather overfitting actually reduce training errors (giving an overly optimistic perspective on the likely performance of a method on new data).</p></li>
<li><p>The test error - decreases as method flexibility increases but then increases again. This is because although the test error decrease as the bias component of the errors decreases, at some point increases in the variance component of the error drives increases in the test error. In other words there is a point at which the advantages of increase flexibility (in terms of reducing the bias component) are outweigh by the disadvantages (in terms of overfitting as the variance component increases.</p></li>
<li><p>The irreducible error - is constant and by definition is the component of the error that is unaffected by method choice and parameterisation.</p></li>
</ul>
<p><strong>Question 4: Examples problems which are well suited to statistical learning methods.</strong></p>
<p>Classification problems:</p>
<ul>
<li><p>Identifying if an email is or is not spam is a problem where predictions are required. The response variable would be flag indicating if an email is spam or not (in the training set this might have been set by manually reviewing the email). The predictor variables would be characteristics of the email for example the use of certain words that are prevalent in spam.</p></li>
<li><p>Explaining difference in the proportion of professors who have tenured. The response variable would be a variable indicating if the professor in question has tenure. The explanatory variables could be characteristic including the gender of the professor, if they have a minority ethnic background etc.</p></li>
<li><p>Predicting if an athlete will win a medal (or not) at the Olympics in a specific event. Predictor variables here could include for example performance at past Olympics, personal bests etc.</p></li>
</ul>
<p>Regression problems:</p>
<ul>
<li><p>Estimating the amount of plastic waste produced by a country. Here predictor variables could include GDP, population, quantitative measure of the maturity of the waste disposal system etc.</p></li>
<li><p>Predicting if a given individual will make use of green spaces in their local area. Here predictor variables might include self-reported health status, age etc.</p></li>
<li><p>Explaining the Green House Gas emission reductions (or increases) delivered by a country. Here predictor values might include GDP per capita, a categorical variable indicating how supportive a countries is at COP meetings, the political leanings of the governing party (on a left-right axis) etc.</p></li>
</ul>
<p>Clustering problems:</p>
<ul>
<li><p>Identifying if there are groups of neighborhoods within a city facing similar problems with citizens accessing green space. Here features for clustering might include the proportion of the population within easy walking distance of public green space, the amount of public green space in the neighborhood, the proportion of the population experiencing disabilities.</p></li>
<li><p>Identifying if there are groups of customer (of a given business) with similar purchasing habit. Here feature for clustering might total spend per month with the business, the frequency of purchases etc.</p></li>
<li><p>Identify if groups of people with similar attitudes to car sharing can be identified from survey responses. Here features for clustering might include Likhert scales responses asking about attitudes to car sharing.</p></li>
</ul>
<p><strong>Question 5: advantages and disadvantages of a very flexible method (relative to an inflexible method).</strong></p>
<p><em>Advantages:</em></p>
<ul>
<li><p>ability to capture non-linear relationships between variables;</p></li>
<li><p>ability to pick up relatively subtle associations between variables;</p></li>
<li><p>can deliver more accurate prediction by modeling more of the complexity of real world systems.</p></li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li><p>prone to overfitting;</p></li>
<li><p>large numbers of data points are required;</p></li>
<li><p>computational intensive;</p></li>
<li><p>can be difficult to interpret the model, and hence not so useful for inference.</p></li>
</ul>
<p><strong>Question 6: parametric and non-parametric methods</strong></p>
<p>A parametric model makes as assumptions about the functional form (i.e. shape) of <em>f.</em> Where <em>f</em> is the function mapping the values of predictor/s to the values of the response variable. Based on these assumptions the general form of the model can be mathematical expressed including the predictor variables and associated co-efficients. Once a parametric model has been selected it can be fit to the data, this reduces to a problem of estimating the coefficients in the mathematical model. The primary advantage of this approach is its simplicity (estimating a set of parameters is much simpler than estimating f itself). The disadvantages are that: it can be difficult to know which model (i.e. shape) to select and picking the wrong model results in poor results; and, that flexible models are prone to overfitting.</p>
<p>A non-parametric model does not make any assumptions about the functional form of <em>f.</em> Rather such models attempt to estimate <em>f</em> by fitting the points as closely as possible, subject to specified constraints on how ‘wiggly’ or smooth a line should result. The main advantage of non-parametric models is that they can fit a wide variety of shapes for <em>f</em> and the analyst does not need to make any <em>a priori</em> guesses about what the associated between predictor and response variables are. However, this advantage comes at the cost of complexity. As the problems of estimating <em>f</em> is not reduced to one of estimating parameters, very large numbers of data points are needed. Also, given non-parametric models are not constrained by assumption about the shape of <em>f</em> then care is needed to avoid overfitting (i.e. an appropriate smoothness constraint must be defined by the analyst).</p>
<p><strong>Question 7: K-nearest neighbors</strong></p>
<p><em>(a):</em> the euclidean distance between each data point and a test point (x<sub>1</sub> = x<sub>2</sub> = x<sub>3</sub> = 0) is shown below.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="statistical-learning.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb11-2"><a href="statistical-learning.html#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="statistical-learning.html#cb11-3" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">&quot;2_7.csv&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb11-4"><a href="statistical-learning.html#cb11-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">dist_from_test_point =</span> <span class="fu">sqrt</span>(x1<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x2<span class="sc">^</span><span class="dv">2</span> <span class="sc">+</span> x3<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb11-5"><a href="statistical-learning.html#cb11-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-6"><a href="statistical-learning.html#cb11-6" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb11-7"><a href="statistical-learning.html#cb11-7" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">obs</th>
<th align="right">x1</th>
<th align="right">x2</th>
<th align="right">x3</th>
<th align="left">y</th>
<th align="right">dist_from_test_point</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0</td>
<td align="right">3</td>
<td align="right">0</td>
<td align="left">Red</td>
<td align="right">3.000000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">2</td>
<td align="right">0</td>
<td align="right">0</td>
<td align="left">Red</td>
<td align="right">2.000000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3</td>
<td align="left">Red</td>
<td align="right">3.162278</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2</td>
<td align="left">Green</td>
<td align="right">2.236068</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">-1</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">Green</td>
<td align="right">1.414214</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="right">1</td>
<td align="left">Red</td>
<td align="right">1.732051</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="statistical-learning.html#cb12-1" aria-hidden="true" tabindex="-1"></a>data <span class="sc">%&gt;%</span> </span>
<span id="cb12-2"><a href="statistical-learning.html#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(obs, dist_from_test_point) <span class="sc">%&gt;%</span> </span>
<span id="cb12-3"><a href="statistical-learning.html#cb12-3" aria-hidden="true" tabindex="-1"></a>  knitr<span class="sc">::</span><span class="fu">kable</span>()</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">obs</th>
<th align="right">dist_from_test_point</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">3.000000</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">2.000000</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">3.162278</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">2.236068</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">1.414214</td>
</tr>
<tr class="even">
<td align="right">6</td>
<td align="right">1.732051</td>
</tr>
</tbody>
</table>
<p><em>(b):</em> Using the k-nearest neighbor method with k = 1 for the test point (x<sub>1</sub> = x<sub>2</sub> = x<sub>3</sub> = 0) the prediction would be the Y value of the nearest point. The nearest point is 5 so the prediction would be <code>Green</code>.</p>
<p><em>(c):</em> If k =3, k-nearest neighbor would look at the three nearest points (y<sub>2</sub> = <code>Red</code>, y<sub>5</sub> = <code>Green</code> and y<sub>6</sub> = <code>Red</code>). The predicted y value would be <code>Red</code> as the majority of the k nearest points have an observed y values of <code>Red</code>.</p>
</div>
<div id="applied-exercises" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Applied Exercises</h2>
<p><strong>Question 8: The Colleges Dataset</strong></p>
<p><em>(a):</em> first I read in the data for the package.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="statistical-learning.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR)</span>
<span id="cb13-2"><a href="statistical-learning.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pander)</span>
<span id="cb13-3"><a href="statistical-learning.html#cb13-3" aria-hidden="true" tabindex="-1"></a>college <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(College)</span></code></pre></div>
<p><em>(b):</em> There college names are already stored as row names</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="statistical-learning.html#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pander</span>(<span class="fu">head</span>(college))</span></code></pre></div>
<table style="width:100%;">
<caption>Table continues below</caption>
<colgroup>
<col width="13%" />
<col width="9%" />
<col width="12%" />
<col width="12%" />
<col width="16%" />
<col width="16%" />
<col width="19%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Private</th>
<th align="center">Apps</th>
<th align="center">Accept</th>
<th align="center">Enroll</th>
<th align="center">Top10perc</th>
<th align="center">Top25perc</th>
<th align="center">F.Undergrad</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Yes</td>
<td align="center">1660</td>
<td align="center">1232</td>
<td align="center">721</td>
<td align="center">23</td>
<td align="center">52</td>
<td align="center">2885</td>
</tr>
<tr class="even">
<td align="center">Yes</td>
<td align="center">2186</td>
<td align="center">1924</td>
<td align="center">512</td>
<td align="center">16</td>
<td align="center">29</td>
<td align="center">2683</td>
</tr>
<tr class="odd">
<td align="center">Yes</td>
<td align="center">1428</td>
<td align="center">1097</td>
<td align="center">336</td>
<td align="center">22</td>
<td align="center">50</td>
<td align="center">1036</td>
</tr>
<tr class="even">
<td align="center">Yes</td>
<td align="center">417</td>
<td align="center">349</td>
<td align="center">137</td>
<td align="center">60</td>
<td align="center">89</td>
<td align="center">510</td>
</tr>
<tr class="odd">
<td align="center">Yes</td>
<td align="center">193</td>
<td align="center">146</td>
<td align="center">55</td>
<td align="center">16</td>
<td align="center">44</td>
<td align="center">249</td>
</tr>
<tr class="even">
<td align="center">Yes</td>
<td align="center">587</td>
<td align="center">479</td>
<td align="center">158</td>
<td align="center">38</td>
<td align="center">62</td>
<td align="center">678</td>
</tr>
</tbody>
</table>
<table>
<caption>Table continues below</caption>
<colgroup>
<col width="18%" />
<col width="14%" />
<col width="17%" />
<col width="10%" />
<col width="14%" />
<col width="8%" />
<col width="14%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">P.Undergrad</th>
<th align="center">Outstate</th>
<th align="center">Room.Board</th>
<th align="center">Books</th>
<th align="center">Personal</th>
<th align="center">PhD</th>
<th align="center">Terminal</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">537</td>
<td align="center">7440</td>
<td align="center">3300</td>
<td align="center">450</td>
<td align="center">2200</td>
<td align="center">70</td>
<td align="center">78</td>
</tr>
<tr class="even">
<td align="center">1227</td>
<td align="center">12280</td>
<td align="center">6450</td>
<td align="center">750</td>
<td align="center">1500</td>
<td align="center">29</td>
<td align="center">30</td>
</tr>
<tr class="odd">
<td align="center">99</td>
<td align="center">11250</td>
<td align="center">3750</td>
<td align="center">400</td>
<td align="center">1165</td>
<td align="center">53</td>
<td align="center">66</td>
</tr>
<tr class="even">
<td align="center">63</td>
<td align="center">12960</td>
<td align="center">5450</td>
<td align="center">450</td>
<td align="center">875</td>
<td align="center">92</td>
<td align="center">97</td>
</tr>
<tr class="odd">
<td align="center">869</td>
<td align="center">7560</td>
<td align="center">4120</td>
<td align="center">800</td>
<td align="center">1500</td>
<td align="center">76</td>
<td align="center">72</td>
</tr>
<tr class="even">
<td align="center">41</td>
<td align="center">13500</td>
<td align="center">3335</td>
<td align="center">500</td>
<td align="center">675</td>
<td align="center">67</td>
<td align="center">73</td>
</tr>
</tbody>
</table>
<table style="width:65%;">
<colgroup>
<col width="16%" />
<col width="19%" />
<col width="12%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">S.F.Ratio</th>
<th align="center">perc.alumni</th>
<th align="center">Expend</th>
<th align="center">Grad.Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">18.1</td>
<td align="center">12</td>
<td align="center">7041</td>
<td align="center">60</td>
</tr>
<tr class="even">
<td align="center">12.2</td>
<td align="center">16</td>
<td align="center">10527</td>
<td align="center">56</td>
</tr>
<tr class="odd">
<td align="center">12.9</td>
<td align="center">30</td>
<td align="center">8735</td>
<td align="center">54</td>
</tr>
<tr class="even">
<td align="center">7.7</td>
<td align="center">37</td>
<td align="center">19016</td>
<td align="center">59</td>
</tr>
<tr class="odd">
<td align="center">11.9</td>
<td align="center">2</td>
<td align="center">10922</td>
<td align="center">15</td>
</tr>
<tr class="even">
<td align="center">9.4</td>
<td align="center">11</td>
<td align="center">9727</td>
<td align="center">55</td>
</tr>
</tbody>
</table>
<p><em>(c):</em> First I produce the summary statistics.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="statistical-learning.html#cb15-1" aria-hidden="true" tabindex="-1"></a>college <span class="sc">%&gt;%</span> </span>
<span id="cb15-2"><a href="statistical-learning.html#cb15-2" aria-hidden="true" tabindex="-1"></a>  skimr<span class="sc">::</span><span class="fu">skim</span>()</span></code></pre></div>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Private</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">Yes: 565, No: 212</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Apps</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3001.64</td>
<td align="right">3870.20</td>
<td align="right">81.0</td>
<td align="right">776.0</td>
<td align="right">1558.0</td>
<td align="right">3624.0</td>
<td align="right">48094.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Accept</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">2018.80</td>
<td align="right">2451.11</td>
<td align="right">72.0</td>
<td align="right">604.0</td>
<td align="right">1110.0</td>
<td align="right">2424.0</td>
<td align="right">26330.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Enroll</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">779.97</td>
<td align="right">929.18</td>
<td align="right">35.0</td>
<td align="right">242.0</td>
<td align="right">434.0</td>
<td align="right">902.0</td>
<td align="right">6392.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Top10perc</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">27.56</td>
<td align="right">17.64</td>
<td align="right">1.0</td>
<td align="right">15.0</td>
<td align="right">23.0</td>
<td align="right">35.0</td>
<td align="right">96.0</td>
<td align="left">▇▇▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">Top25perc</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">55.80</td>
<td align="right">19.80</td>
<td align="right">9.0</td>
<td align="right">41.0</td>
<td align="right">54.0</td>
<td align="right">69.0</td>
<td align="right">100.0</td>
<td align="left">▂▆▇▅▃</td>
</tr>
<tr class="even">
<td align="left">F.Undergrad</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3699.91</td>
<td align="right">4850.42</td>
<td align="right">139.0</td>
<td align="right">992.0</td>
<td align="right">1707.0</td>
<td align="right">4005.0</td>
<td align="right">31643.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">P.Undergrad</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">855.30</td>
<td align="right">1522.43</td>
<td align="right">1.0</td>
<td align="right">95.0</td>
<td align="right">353.0</td>
<td align="right">967.0</td>
<td align="right">21836.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">Outstate</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">10440.67</td>
<td align="right">4023.02</td>
<td align="right">2340.0</td>
<td align="right">7320.0</td>
<td align="right">9990.0</td>
<td align="right">12925.0</td>
<td align="right">21700.0</td>
<td align="left">▃▇▆▂▂</td>
</tr>
<tr class="odd">
<td align="left">Room.Board</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4357.53</td>
<td align="right">1096.70</td>
<td align="right">1780.0</td>
<td align="right">3597.0</td>
<td align="right">4200.0</td>
<td align="right">5050.0</td>
<td align="right">8124.0</td>
<td align="left">▂▇▆▂▁</td>
</tr>
<tr class="even">
<td align="left">Books</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">549.38</td>
<td align="right">165.11</td>
<td align="right">96.0</td>
<td align="right">470.0</td>
<td align="right">500.0</td>
<td align="right">600.0</td>
<td align="right">2340.0</td>
<td align="left">▇▆▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Personal</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1340.64</td>
<td align="right">677.07</td>
<td align="right">250.0</td>
<td align="right">850.0</td>
<td align="right">1200.0</td>
<td align="right">1700.0</td>
<td align="right">6800.0</td>
<td align="left">▇▃▁▁▁</td>
</tr>
<tr class="even">
<td align="left">PhD</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">72.66</td>
<td align="right">16.33</td>
<td align="right">8.0</td>
<td align="right">62.0</td>
<td align="right">75.0</td>
<td align="right">85.0</td>
<td align="right">103.0</td>
<td align="left">▁▁▅▇▅</td>
</tr>
<tr class="odd">
<td align="left">Terminal</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">79.70</td>
<td align="right">14.72</td>
<td align="right">24.0</td>
<td align="right">71.0</td>
<td align="right">82.0</td>
<td align="right">92.0</td>
<td align="right">100.0</td>
<td align="left">▁▁▃▆▇</td>
</tr>
<tr class="even">
<td align="left">S.F.Ratio</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">14.09</td>
<td align="right">3.96</td>
<td align="right">2.5</td>
<td align="right">11.5</td>
<td align="right">13.6</td>
<td align="right">16.5</td>
<td align="right">39.8</td>
<td align="left">▁▇▂▁▁</td>
</tr>
<tr class="odd">
<td align="left">perc.alumni</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">22.74</td>
<td align="right">12.39</td>
<td align="right">0.0</td>
<td align="right">13.0</td>
<td align="right">21.0</td>
<td align="right">31.0</td>
<td align="right">64.0</td>
<td align="left">▅▇▆▂▁</td>
</tr>
<tr class="even">
<td align="left">Expend</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">9660.17</td>
<td align="right">5221.77</td>
<td align="right">3186.0</td>
<td align="right">6751.0</td>
<td align="right">8377.0</td>
<td align="right">10830.0</td>
<td align="right">56233.0</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">Grad.Rate</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">65.46</td>
<td align="right">17.18</td>
<td align="right">10.0</td>
<td align="right">53.0</td>
<td align="right">65.0</td>
<td align="right">78.0</td>
<td align="right">118.0</td>
<td align="left">▁▅▇▅▁</td>
</tr>
</tbody>
</table>
<p>Then produce a scatter plot matrix for the first 10 variables.</p>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p><em>(c):</em> next is to plot side by side boxplots of <code>outstate</code> vs <code>private</code></p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="statistical-learning.html#cb16-1" aria-hidden="true" tabindex="-1"></a>college <span class="sc">%&gt;%</span> </span>
<span id="cb16-2"><a href="statistical-learning.html#cb16-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Outstate, <span class="at">y =</span> Private)) <span class="sc">+</span></span>
<span id="cb16-3"><a href="statistical-learning.html#cb16-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb16-4"><a href="statistical-learning.html#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb16-5"><a href="statistical-learning.html#cb16-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb16-6"><a href="statistical-learning.html#cb16-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Private university?&quot;</span>,</span>
<span id="cb16-7"><a href="statistical-learning.html#cb16-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Number of out of state students&quot;</span>,</span>
<span id="cb16-8"><a href="statistical-learning.html#cb16-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Private universities tend to have more out of state students&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p><em>(iv):</em> next is looking at universities with high proportions of students from elite high schools.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="statistical-learning.html#cb17-1" aria-hidden="true" tabindex="-1"></a>college <span class="sc">%&gt;%</span> </span>
<span id="cb17-2"><a href="statistical-learning.html#cb17-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">elite =</span> <span class="fu">if_else</span>(Top10perc <span class="sc">&gt;</span> <span class="dv">50</span>,</span>
<span id="cb17-3"><a href="statistical-learning.html#cb17-3" aria-hidden="true" tabindex="-1"></a>                         <span class="cn">TRUE</span>,</span>
<span id="cb17-4"><a href="statistical-learning.html#cb17-4" aria-hidden="true" tabindex="-1"></a>                         <span class="cn">FALSE</span>)) <span class="sc">%&gt;%</span> </span>
<span id="cb17-5"><a href="statistical-learning.html#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(elite) <span class="sc">%&gt;%</span> </span>
<span id="cb17-6"><a href="statistical-learning.html#cb17-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">n =</span> <span class="fu">n</span>())</span></code></pre></div>
<pre><code>## # A tibble: 2 x 2
##   elite     n
##   &lt;lgl&gt; &lt;int&gt;
## 1 FALSE   699
## 2 TRUE     78</code></pre>
<p><em>(v):</em> next looking at producing some histograms for a couple of continuous variables of interest (full and part time undergraduates)</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="statistical-learning.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb19-2"><a href="statistical-learning.html#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="statistical-learning.html#cb19-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> college <span class="sc">%&gt;%</span> </span>
<span id="cb19-4"><a href="statistical-learning.html#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(F.Undergrad, P.Undergrad) <span class="sc">%&gt;%</span> </span>
<span id="cb19-5"><a href="statistical-learning.html#cb19-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">id =</span> <span class="fu">row_number</span>(), <span class="at">.before =</span> F.Undergrad) <span class="sc">%&gt;%</span> </span>
<span id="cb19-6"><a href="statistical-learning.html#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(F.Undergrad, P.Undergrad), </span>
<span id="cb19-7"><a href="statistical-learning.html#cb19-7" aria-hidden="true" tabindex="-1"></a>               <span class="at">names_to =</span> <span class="st">&quot;student_status&quot;</span>, </span>
<span id="cb19-8"><a href="statistical-learning.html#cb19-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">values_to =</span> <span class="st">&quot;number_of_students&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb19-9"><a href="statistical-learning.html#cb19-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-10"><a href="statistical-learning.html#cb19-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(number_of_students)) <span class="sc">+</span></span>
<span id="cb19-11"><a href="statistical-learning.html#cb19-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">fill =</span> student_status), <span class="at">bins =</span> <span class="dv">100</span>) <span class="sc">+</span></span>
<span id="cb19-12"><a href="statistical-learning.html#cb19-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>student_status) <span class="sc">+</span></span>
<span id="cb19-13"><a href="statistical-learning.html#cb19-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">fill =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb19-14"><a href="statistical-learning.html#cb19-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Number of students attending&quot;</span>,</span>
<span id="cb19-15"><a href="statistical-learning.html#cb19-15" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Number of universities&quot;</span>)</span>
<span id="cb19-16"><a href="statistical-learning.html#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="statistical-learning.html#cb19-17" aria-hidden="true" tabindex="-1"></a>p_zoom <span class="ot">&lt;-</span> p <span class="sc">+</span> <span class="fu">coord_cartesian</span>(<span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">2500</span>)) <span class="sc">+</span></span>
<span id="cb19-18"><a href="statistical-learning.html#cb19-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">subtitle =</span> <span class="st">&quot;Zooming on smaller cohort sizes&quot;</span>)</span>
<span id="cb19-19"><a href="statistical-learning.html#cb19-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-20"><a href="statistical-learning.html#cb19-20" aria-hidden="true" tabindex="-1"></a>p <span class="sc">/</span> p_zoom <span class="sc">+</span></span>
<span id="cb19-21"><a href="statistical-learning.html#cb19-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">plot_annotation</span>(<span class="at">title =</span> <span class="st">&quot;Differing frequencies of full and part-time students cohort sizes&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p><em>(vi):</em> Continuing the exploratory data analysis, my key findings were as follows:</p>
<ul>
<li>Private universities appear to have higher graduation rates than public universities.</li>
</ul>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="statistical-learning.html#cb20-1" aria-hidden="true" tabindex="-1"></a>college <span class="sc">%&gt;%</span> </span>
<span id="cb20-2"><a href="statistical-learning.html#cb20-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-3"><a href="statistical-learning.html#cb20-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># remove an outlier with impossible graduation rate</span></span>
<span id="cb20-4"><a href="statistical-learning.html#cb20-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Grad.Rate <span class="sc">&lt;=</span> <span class="dv">100</span>) <span class="sc">%&gt;%</span></span>
<span id="cb20-5"><a href="statistical-learning.html#cb20-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-6"><a href="statistical-learning.html#cb20-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># produce plot base</span></span>
<span id="cb20-7"><a href="statistical-learning.html#cb20-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(Private, Grad.Rate)) <span class="sc">+</span></span>
<span id="cb20-8"><a href="statistical-learning.html#cb20-8" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-9"><a href="statistical-learning.html#cb20-9" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add data points as background layer</span></span>
<span id="cb20-10"><a href="statistical-learning.html#cb20-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">colour =</span> <span class="st">&quot;lightblue&quot;</span>) <span class="sc">+</span></span>
<span id="cb20-11"><a href="statistical-learning.html#cb20-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">fill =</span> <span class="cn">NA</span>, <span class="at">outlier.shape =</span> <span class="cn">NA</span>,</span>
<span id="cb20-12"><a href="statistical-learning.html#cb20-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb20-13"><a href="statistical-learning.html#cb20-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb20-14"><a href="statistical-learning.html#cb20-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add labels</span></span>
<span id="cb20-15"><a href="statistical-learning.html#cb20-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Private university?&quot;</span>,</span>
<span id="cb20-16"><a href="statistical-learning.html#cb20-16" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Graduation rate&quot;</span>,</span>
<span id="cb20-17"><a href="statistical-learning.html#cb20-17" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Private universities appear to have higher graduation rates</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<ul>
<li>More selective universities appear to have higher graduation rates.</li>
</ul>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="statistical-learning.html#cb21-1" aria-hidden="true" tabindex="-1"></a>college <span class="sc">%&gt;%</span> </span>
<span id="cb21-2"><a href="statistical-learning.html#cb21-2" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-3"><a href="statistical-learning.html#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span class="co"># remove an outlier with impossible graduation rate</span></span>
<span id="cb21-4"><a href="statistical-learning.html#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(Grad.Rate <span class="sc">&lt;=</span> <span class="dv">100</span>) <span class="sc">%&gt;%</span></span>
<span id="cb21-5"><a href="statistical-learning.html#cb21-5" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-6"><a href="statistical-learning.html#cb21-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># create plot base</span></span>
<span id="cb21-7"><a href="statistical-learning.html#cb21-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="fu">cut_width</span>(Accept <span class="sc">/</span> Apps <span class="sc">*</span> <span class="dv">100</span>, </span>
<span id="cb21-8"><a href="statistical-learning.html#cb21-8" aria-hidden="true" tabindex="-1"></a>                       <span class="at">width =</span> <span class="dv">20</span>,</span>
<span id="cb21-9"><a href="statistical-learning.html#cb21-9" aria-hidden="true" tabindex="-1"></a>                       <span class="at">boundary =</span> <span class="dv">0</span>), Grad.Rate)) <span class="sc">+</span></span>
<span id="cb21-10"><a href="statistical-learning.html#cb21-10" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-11"><a href="statistical-learning.html#cb21-11" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add data points as a background layer</span></span>
<span id="cb21-12"><a href="statistical-learning.html#cb21-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">colour =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">width =</span> <span class="fl">0.2</span>)<span class="sc">+</span></span>
<span id="cb21-13"><a href="statistical-learning.html#cb21-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-14"><a href="statistical-learning.html#cb21-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add boxplots</span></span>
<span id="cb21-15"><a href="statistical-learning.html#cb21-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">width =</span> <span class="fl">0.2</span>, <span class="at">alpha =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb21-16"><a href="statistical-learning.html#cb21-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-17"><a href="statistical-learning.html#cb21-17" aria-hidden="true" tabindex="-1"></a>  <span class="co"># format scales for readability</span></span>
<span id="cb21-18"><a href="statistical-learning.html#cb21-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_discrete</span>(<span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;0-19%&quot;</span>, <span class="st">&quot;20-39%&quot;</span>, <span class="st">&quot;40-59%&quot;</span>, <span class="st">&quot;60-79%&quot;</span>, <span class="st">&quot;80-100%&quot;</span>)) <span class="sc">+</span></span>
<span id="cb21-19"><a href="statistical-learning.html#cb21-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">percent_format</span>(<span class="at">scale =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb21-20"><a href="statistical-learning.html#cb21-20" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb21-21"><a href="statistical-learning.html#cb21-21" aria-hidden="true" tabindex="-1"></a>  <span class="co"># add labels</span></span>
<span id="cb21-22"><a href="statistical-learning.html#cb21-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;</span><span class="sc">\n</span><span class="st">Percentage of applications accepted&quot;</span>,</span>
<span id="cb21-23"><a href="statistical-learning.html#cb21-23" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Percentage of students graduating</span><span class="sc">\n</span><span class="st">&quot;</span>,</span>
<span id="cb21-24"><a href="statistical-learning.html#cb21-24" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;More selective universities appear to have higher graduation rates</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p><strong>Question 9: The Auto dataset</strong></p>
<p><em>(a):</em></p>
<ul>
<li><p>Quantitative predictors: <code>mpg</code>, <code>cylinders</code>, <code>displacement</code>, <code>horsepower</code>, <code>weight</code>, <code>acceleration</code>, <code>year</code> and <code>origin</code>.</p></li>
<li><p>Qualitative predictor: <code>name.</code></p></li>
</ul>
<p><em>(b):</em> The range for each quantiative variable is shown in the skim dataframe below (p0 corresponds to the minimum and p100 corresponds to the maximum).</p>
<p><em>(c):</em> The mean and standard deviations for each quantiative variable is shown in the skim dataframe below.</p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="statistical-learning.html#cb22-1" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(Auto) <span class="sc">%&gt;%</span> </span>
<span id="cb22-2"><a href="statistical-learning.html#cb22-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>n_missing, <span class="sc">-</span>complete_rate)</span></code></pre></div>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">name</td>
<td align="left">FALSE</td>
<td align="right">301</td>
<td align="left">amc: 5, for: 5, toy: 5, amc: 4</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">mpg</td>
<td align="right">23.45</td>
<td align="right">7.81</td>
<td align="right">9</td>
<td align="right">17.00</td>
<td align="right">22.75</td>
<td align="right">29.00</td>
<td align="right">46.6</td>
<td align="left">▆▇▆▃▁</td>
</tr>
<tr class="even">
<td align="left">cylinders</td>
<td align="right">5.47</td>
<td align="right">1.71</td>
<td align="right">3</td>
<td align="right">4.00</td>
<td align="right">4.00</td>
<td align="right">8.00</td>
<td align="right">8.0</td>
<td align="left">▇▁▃▁▅</td>
</tr>
<tr class="odd">
<td align="left">displacement</td>
<td align="right">194.41</td>
<td align="right">104.64</td>
<td align="right">68</td>
<td align="right">105.00</td>
<td align="right">151.00</td>
<td align="right">275.75</td>
<td align="right">455.0</td>
<td align="left">▇▂▂▃▁</td>
</tr>
<tr class="even">
<td align="left">horsepower</td>
<td align="right">104.47</td>
<td align="right">38.49</td>
<td align="right">46</td>
<td align="right">75.00</td>
<td align="right">93.50</td>
<td align="right">126.00</td>
<td align="right">230.0</td>
<td align="left">▆▇▃▁▁</td>
</tr>
<tr class="odd">
<td align="left">weight</td>
<td align="right">2977.58</td>
<td align="right">849.40</td>
<td align="right">1613</td>
<td align="right">2225.25</td>
<td align="right">2803.50</td>
<td align="right">3614.75</td>
<td align="right">5140.0</td>
<td align="left">▇▇▅▅▂</td>
</tr>
<tr class="even">
<td align="left">acceleration</td>
<td align="right">15.54</td>
<td align="right">2.76</td>
<td align="right">8</td>
<td align="right">13.78</td>
<td align="right">15.50</td>
<td align="right">17.02</td>
<td align="right">24.8</td>
<td align="left">▁▆▇▂▁</td>
</tr>
<tr class="odd">
<td align="left">year</td>
<td align="right">75.98</td>
<td align="right">3.68</td>
<td align="right">70</td>
<td align="right">73.00</td>
<td align="right">76.00</td>
<td align="right">79.00</td>
<td align="right">82.0</td>
<td align="left">▇▆▇▆▇</td>
</tr>
<tr class="even">
<td align="left">origin</td>
<td align="right">1.58</td>
<td align="right">0.81</td>
<td align="right">1</td>
<td align="right">1.00</td>
<td align="right">1.00</td>
<td align="right">2.00</td>
<td align="right">3.0</td>
<td align="left">▇▁▂▁▂</td>
</tr>
</tbody>
</table>
<p><em>(d):</em> The means and standard deviations for the quantitative variables for the dataset (minus the 10th and 85th rows) are shown in the skim dataframe below.</p>
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="statistical-learning.html#cb23-1" aria-hidden="true" tabindex="-1"></a>autos_omit <span class="ot">&lt;-</span> <span class="fu">slice</span>(Auto, <span class="sc">-</span><span class="dv">10</span>, <span class="sc">-</span><span class="dv">85</span>)</span>
<span id="cb23-2"><a href="statistical-learning.html#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="statistical-learning.html#cb23-3" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(autos_omit) <span class="sc">%&gt;%</span> </span>
<span id="cb23-4"><a href="statistical-learning.html#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>n_missing, <span class="sc">-</span>complete_rate)</span></code></pre></div>
<p><strong>Variable type: factor</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">name</td>
<td align="left">FALSE</td>
<td align="right">299</td>
<td align="left">amc: 5, for: 5, toy: 5, amc: 4</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">mpg</td>
<td align="right">23.49</td>
<td align="right">7.80</td>
<td align="right">9</td>
<td align="right">17.50</td>
<td align="right">23.0</td>
<td align="right">29.00</td>
<td align="right">46.6</td>
<td align="left">▆▇▆▃▁</td>
</tr>
<tr class="even">
<td align="left">cylinders</td>
<td align="right">5.46</td>
<td align="right">1.70</td>
<td align="right">3</td>
<td align="right">4.00</td>
<td align="right">4.0</td>
<td align="right">8.00</td>
<td align="right">8.0</td>
<td align="left">▇▁▃▁▃</td>
</tr>
<tr class="odd">
<td align="left">displacement</td>
<td align="right">193.51</td>
<td align="right">104.14</td>
<td align="right">68</td>
<td align="right">105.00</td>
<td align="right">148.5</td>
<td align="right">262.00</td>
<td align="right">455.0</td>
<td align="left">▇▂▂▃▁</td>
</tr>
<tr class="even">
<td align="left">horsepower</td>
<td align="right">104.07</td>
<td align="right">38.18</td>
<td align="right">46</td>
<td align="right">75.00</td>
<td align="right">92.5</td>
<td align="right">125.00</td>
<td align="right">230.0</td>
<td align="left">▆▇▃▁▁</td>
</tr>
<tr class="odd">
<td align="left">weight</td>
<td align="right">2972.47</td>
<td align="right">848.51</td>
<td align="right">1613</td>
<td align="right">2223.75</td>
<td align="right">2797.5</td>
<td align="right">3608.00</td>
<td align="right">5140.0</td>
<td align="left">▇▇▅▅▂</td>
</tr>
<tr class="even">
<td align="left">acceleration</td>
<td align="right">15.57</td>
<td align="right">2.74</td>
<td align="right">8</td>
<td align="right">13.83</td>
<td align="right">15.5</td>
<td align="right">17.08</td>
<td align="right">24.8</td>
<td align="left">▁▆▇▂▁</td>
</tr>
<tr class="odd">
<td align="left">year</td>
<td align="right">76.00</td>
<td align="right">3.68</td>
<td align="right">70</td>
<td align="right">73.00</td>
<td align="right">76.0</td>
<td align="right">79.00</td>
<td align="right">82.0</td>
<td align="left">▇▆▇▆▇</td>
</tr>
<tr class="even">
<td align="left">origin</td>
<td align="right">1.58</td>
<td align="right">0.81</td>
<td align="right">1</td>
<td align="right">1.00</td>
<td align="right">1.0</td>
<td align="right">2.00</td>
<td align="right">3.0</td>
<td align="left">▇▁▂▁▂</td>
</tr>
</tbody>
</table>
<p><em>(e and f):</em> The correlation plot below shows a high degree of correlation between four predictor variables (<code>cylinders</code>, <code>displacement</code>, <code>horsepower</code> and <code>weight</code>). There is also a high degree of correlation between these three predictors and the response variable (<code>mpg</code>).</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="statistical-learning.html#cb24-1" aria-hidden="true" tabindex="-1"></a>GGally<span class="sc">::</span><span class="fu">ggcorr</span>(Auto, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>Scatter plots can help use look at these four predictor variables in more detail.</p>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="statistical-learning.html#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Auto,</span>
<span id="cb25-2"><a href="statistical-learning.html#cb25-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(<span class="fu">factor</span>(cylinders), mpg)) <span class="sc">+</span></span>
<span id="cb25-3"><a href="statistical-learning.html#cb25-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="at">colour =</span> <span class="st">&quot;lightblue&quot;</span>, <span class="at">width =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb25-4"><a href="statistical-learning.html#cb25-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">width =</span> <span class="fl">0.3</span>, <span class="at">alpha =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb25-5"><a href="statistical-learning.html#cb25-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;</span><span class="sc">\n</span><span class="st">Number of Cylinders&quot;</span>,</span>
<span id="cb25-6"><a href="statistical-learning.html#cb25-6" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Fuel economy (mpg)</span><span class="sc">\n</span><span class="st">&quot;</span>,</span>
<span id="cb25-7"><a href="statistical-learning.html#cb25-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;There is a negative association between the number of cylinders</span><span class="sc">\n</span><span class="st">and fuel economy</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-16-1.png" width="672" /></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="statistical-learning.html#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Auto,</span>
<span id="cb26-2"><a href="statistical-learning.html#cb26-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(displacement, mpg)) <span class="sc">+</span></span>
<span id="cb26-3"><a href="statistical-learning.html#cb26-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb26-4"><a href="statistical-learning.html#cb26-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb26-5"><a href="statistical-learning.html#cb26-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>, <span class="dv">100</span>, <span class="dv">200</span>, <span class="dv">400</span>)) <span class="sc">+</span></span>
<span id="cb26-6"><a href="statistical-learning.html#cb26-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand_limits</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb26-7"><a href="statistical-learning.html#cb26-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;</span><span class="sc">\n</span><span class="st">Engine displacement (on a log transformed scale)</span><span class="sc">\n</span><span class="st">&quot;</span>,</span>
<span id="cb26-8"><a href="statistical-learning.html#cb26-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Fuel economy (mpg)</span><span class="sc">\n</span><span class="st">&quot;</span>,</span>
<span id="cb26-9"><a href="statistical-learning.html#cb26-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;There is a negative association between the</span><span class="sc">\n</span><span class="st">logarithm of engine displacement and fuel economy</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-17-1.png" width="672" /></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="statistical-learning.html#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Auto,</span>
<span id="cb27-2"><a href="statistical-learning.html#cb27-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(horsepower, mpg)) <span class="sc">+</span></span>
<span id="cb27-3"><a href="statistical-learning.html#cb27-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb27-4"><a href="statistical-learning.html#cb27-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb27-5"><a href="statistical-learning.html#cb27-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>() <span class="sc">+</span></span>
<span id="cb27-6"><a href="statistical-learning.html#cb27-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">expand_limits</span>(<span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb27-7"><a href="statistical-learning.html#cb27-7" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb27-8"><a href="statistical-learning.html#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Horsepower (on a log scale)&quot;</span>,</span>
<span id="cb27-9"><a href="statistical-learning.html#cb27-9" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Fuel Economy (mpg)&quot;</span>,</span>
<span id="cb27-10"><a href="statistical-learning.html#cb27-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;There is a negative association between the</span><span class="sc">\n</span><span class="st">logarithm of horsepower and fuel economy</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-18-1.png" width="672" /></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="statistical-learning.html#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(Auto,</span>
<span id="cb28-2"><a href="statistical-learning.html#cb28-2" aria-hidden="true" tabindex="-1"></a>       <span class="fu">aes</span>(weight, mpg)) <span class="sc">+</span></span>
<span id="cb28-3"><a href="statistical-learning.html#cb28-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb28-4"><a href="statistical-learning.html#cb28-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb28-5"><a href="statistical-learning.html#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>() <span class="sc">+</span></span>
<span id="cb28-6"><a href="statistical-learning.html#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Weight in kgs (on a log scale)&quot;</span>,</span>
<span id="cb28-7"><a href="statistical-learning.html#cb28-7" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Fuel economy (mpg)&quot;</span>,</span>
<span id="cb28-8"><a href="statistical-learning.html#cb28-8" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;There is a negative association between the</span><span class="sc">\n</span><span class="st">logarithm of weight and fuel economy</span><span class="sc">\n</span><span class="st">&quot;</span>)</span></code></pre></div>
<p><img src="02_Statistical_Learning_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<p>Each of the four variables plotted above could be useful predictors of fuel economy. Additionally, the correlation plot also identified two other variables with reasonably strong correlations with fuel economy: <code>year</code> and <code>origin</code>. If I was going to proceed to develop a model using this data, it would be worth looking at <code>year</code> and <code>origin</code> in more detail.</p>
<p><strong>Question 8: The Boston Housing dataset.</strong></p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="linear-regression.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/rstudio/bookdown-demo/edit/master/02_Statistical_Learning.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown-demo.pdf", "bookdown-demo.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
