# Linear Regression

```{r}
library(MASS) # For Boston data set
library(tidymodels)
library(ISLR)
library(tidyverse)
```

```{r, include = FALSE}
# global settings for producing html output
knitr::opts_chunk$set(warning = FALSE,                  # remove for readability
                      message = FALSE,                  # remove for readability
                      skimr_include_summary = FALSE,    # remove for readability
                      cache = TRUE)   # for inclusion during coding

# set default theme for plots
theme_set(theme_minimal())
```

## Lab

[Based on ISLR tidymodels Labs](https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/linear-regression.html)

```{r}
```

A simple linear regression model

```{r}
# specify the model
lm_spec <- parsnip::linear_reg() %>% 
  parsnip::set_mode("regression") %>% 
  parsnip::set_engine("stan")

lm_spec

# fit the model
lm_fit <- lm_spec %>% 
  parsnip::fit(medv ~ lstat, data = Boston)

lm_fit

# examine the fit
lm_fit$fit

# in more details
lm_fit %>% 
  purrr::pluck("fit") %>% 
  summary()

# get tidy output from model fit
broom.mixed::tidy(lm_fit)
broom.mixed::glance(lm_fit)

broom.mixed::tidy(lm_fit$fit)
broom.mixed::glance(lm_fit$fit)

# predict medv for the training set
stats::predict(lm_fit, new_data = Boston, type = "conf_int") %>% 
  dplyr::bind_cols(Boston) %>% 
  dplyr::select(medv, tidyr::starts_with(".pred"))

# predict and compare to actual is less code
broom::augment(lm_fit, new_data = Boston) %>% 
  dplyr::select(medv, `.pred`)
```

A multiple linear regression model.

```{r}
# specify the model
lm_spec_2 <- parsnip::linear_reg() %>% 
  parsnip::set_mode("regression") %>% 
  parsnip::set_engine("lm")

# fit the model
lm_fit_2 <- lm_spec_2 %>% 
  parsnip::fit(medv ~ lstat + age,
               data = Boston)

# look at the output
summary(lm_fit_2$fit)
broom::tidy(lm_fit_2)

broom::augment(lm_fit_2, new_data = Boston) %>% 
  dplyr::select(medv, .pred)
```

A more complicated linear regression model.

```{r}
# fit the model using all available varaibles as predictors
lm_fit_3 <- lm_spec_2 %>% 
  fit(medv ~ ., Boston)

# look at modle fit output
tidy(lm_fit_3) %>% 
  filter(p.value < 0.05)
```

Interaction terms in formula

```{r}
# fit a model with an interaction specfied in the formula
lm_fit_4 <- lm_spec_2 %>% 
  parsnip::fit(medv ~ lstat * age, data = Boston)

# look at the model fit output in a tidy form
broom::tidy(lm_fit_4)
```

Interactions terms using `recipes`.

```{r}
# specify the interaction using recipes
rec_spec <- recipes::recipe(medv ~ lstat + age, data = Boston) %>% 
  recipes::step_interact(terms = ~ lstat:age)

# create a modelling workflow
lm_wf <- workflows::workflow() %>% 
  add_model(lm_spec) %>% 
  add_recipe(rec_spec)

# run the workflow
lm_wf_out <- lm_wf %>% 
  parsnip::fit(Boston)

tidy(lm_wf_out)
glance(lm_wf_out)

# get the actual model fit
lm_wf_out$fit$fit$fit
```

Applying non-linear transformations to predictors

```{r}
# create a new recipe
rec_spec_pow2 <- recipes::recipe(medv ~ lstat, data = Boston) %>% 
  step_mutate(lstat = lstat ^ 2)

# create a new workflow including the new recipe
lm_wf_pow2 <- workflows::workflow() %>% 
  add_model(lm_spec) %>% 
  add_recipe(rec_spec_pow2)

# fit the workflow
lm_wf_pow2 %>% 
  fit(data = Boston)
```

Using predefined steps from `recipes`.

```{r}
# create different recipe
rec_spec_log <- recipes::recipe(medv ~ lstat, data = Boston) %>% 
  step_log(lstat)

# create a workflow incorporating this recipe
lm_wf_log <- workflows::workflow() %>% 
  add_model(lm_spec) %>% 
  add_recipe(rec_spec_log)

# run the workflow
lm_wf_log %>% 
  fit(data = Boston)
```

Dealing with qualitative predictors. Many models convert qualitative predictors to dummy variables automatically, so qualitative predictors can just be added the formula. But if not, dummy variables can be created in the recipe.

```{r}
# look at the dataset used in the lab 
Carseats

# create a recipe
rec_spec <- recipes::recipe(Sales ~ ., data = Carseats) %>% 
  step_dummy(all_nominal()) %>% 
  step_interact(~ Income:Advertising + Price:Age)

# create a workflow
carseats_wf <- workflows::workflow() %>% 
  add_model(lm_spec_2) %>% 
  add_recipe(rec_spec)

# run the workflow
wf_out <- carseats_wf %>% 
  fit(Carseats)

tidy(wf_out) #%>% 
 #kableExtra::kable()
```

## Conceptual questions

**Question 1: null hypotheses for p-values in Table 3.4**

Each of the four p-values in table 3.4 relate to the null hypotheses that each corresponding coefficient is zero. Based on these p-values we can conclude that there is strong evidence that the `Intercept`, and the `TV` and `Radio` predictors are non zero. That is the null hypotheses corresponding to each of these coefficients can be rejected. Or in other words, the `TV` and `Radio` variables can be helpful in predicting `Sales`. We cannot reject the null hypothesis associated the `Newspaper` variable, as the corresponding p-value is greater than 1 minus the confidence level (assumed to be 95% in this case). In other words there is not strong evidence that `Newspaper` (in conjuction with the other predictors) can be helpful in predicting `Sales`.

**Question 2: differences between KNN classifier and KNN regression methods**

The key differences between the KNN classifier and KNN regression methods can be summarized as follows:

-   For the KNN classifier the predicted value is a class (i.e. a qualitative value) whereas for the KNN regression the predicted value is numerical (i.e. a continuous numerical value).

-   When using the classifier method, the predicted class is determined by considering the number of K nearest neighbors which fall in each class. The class with the largest number of K nearest neighbors is taken as the prediction. Whereas, when using the regression method, the predicted class is determined by averaging the values of the response variable for the K nearest neighbors.

**Question 3: interpreting coefficients**

*(a):* It is likely that (ii) is correct. The coefficient for the main effect gender is positive (B~3~ is 35), so for a fixed value of GPA and IQ we would expect females to earn more. There is an interaction term, between GPA and gender but this is not relevant because we are assuming GPA is a fixed value.

*(b)*:

```{r}
gender <- 1
IQ <- 110
GPA <- 4.0

salary <- 50 + (20 * GPA) + (0.07 * IQ) + (35 * gender) + (0.01 * GPA * IQ) + (-10 * GPA * gender)

salary
```

*(c)*: True - given the GPA/IQ coefficient is very small it is unlikely that it's p-value would show statistical significant, because assume the standard error of the coefficient is non-zero the confidence interval for the coefficient will encompass zero.

**Question 4: linear versus cubic regression**

*(a):* For the training set, I don't think there is enough information to be confident about the question of if the RSS would be lower for the linear or cubic regression. It would depend on if the noise in the data, on top of the underlying linear relationship, created a resemblance to a cubic relationship between the predictor and response variable.

*(b):* For the test set, I would expect the linear regression to have a lower RSS than the cubic regression. This is because cubic regression (as the more flexible method) would have been more likely to over fit the data.

*(c):* If we assume the underlying relationship is non linear, again I think there is not enough information to be confident about the question of if the RSS would be lower for the linear or cubic regression. It would depend on whether the assumed functional form of the linear and cubic models is closer to the true underlying relationship.

*(d):* Again for the test, it would depend on whether the assumed functional form of the linear and cubic models is closer to the true underlying relationship.

**Question 5**

Answer in notebook.

## Applied questions
